{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ <b><u>Exercise objectives</u></b>\n",
    "- Understand the *MNIST* dataset \n",
    "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
    "    - what are *Convolutional Layers* ? \n",
    "    - how many *parameters* are involved in such a layer ?\n",
    "- Train this CNN on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ <b><u>Let's get started !</u></b>\n",
    "\n",
    "Imagine that we are  back in time into the 90's.\n",
    "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits ? \n",
    "\n",
    "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, *Yann Le Cun* used to work.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
    "\n",
    "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Number recognition](recognition.gif)\n",
    "\n",
    "*Nota Bene: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, the CNN predicts what digit is written. The inputs are the different digits and not one animation/video!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î <b><u>How does this CNN work ?</u></b>\n",
    "\n",
    "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
    "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
    "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
    "\n",
    "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**] üìö(http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
    "- *Vectors*: `boston_housing` (regression)\n",
    "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
    "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
    "\n",
    "\n",
    "üíæ You can **load the MNIST dataset** with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
    "\n",
    "üñ® Print some images from the *train set*.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hints</i></summary>\n",
    "\n",
    "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
    "\n",
    "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just some arrangements done Matplotlib...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(X_train.shape)\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(X_train[0], cmap=\"gray\");\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.imshow(X_train[1], cmap=\"gray\");\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train[2], cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
    "\n",
    "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
    "* The `RBG` intensities are coded between 0 and 255. \n",
    "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: As a first preprocessing step, please normalize your data.** ‚ùì\n",
    "\n",
    "Don't forget to do it both on your train data and your test data.\n",
    "\n",
    "(*NB: you can also center your data, by substracting 0.5 from all the values, but it is not mandatory*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/kg_lz68s1zj3pt6_vd9xx4wr0000gn/T/ipykernel_62226/2678432671.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  X_test = X_test/X_train.mean(axis=0)\n",
      "/var/folders/y9/kg_lz68s1zj3pt6_vd9xx4wr0000gn/T/ipykernel_62226/2678432671.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_test = X_test/X_train.mean(axis=0)\n",
      "/var/folders/y9/kg_lz68s1zj3pt6_vd9xx4wr0000gn/T/ipykernel_62226/2678432671.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_train = X_train/X_train.mean(axis=0)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X_test = X_test/X_train.mean(axis=0)\n",
    "X_train = X_train/X_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: What is the shape of your images** ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ You see that you have 60.000 training images, all of size $(28, 28)$. However...\n",
    "\n",
    "‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`** ‚ùóÔ∏è\n",
    "\n",
    "This last dimension is clearly missing here... Can you guess the reason why ?\n",
    "\n",
    "<details>\n",
    "    <summary><i>Answer<i></summary>\n",
    "        \n",
    "* All these $60000$ $ 28 \\times 28 $ pictures are black-and-white. $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1)\n",
    "        \n",
    "* Theoretically, you don't need to know the number of channels unlike colored pictures using for example:\n",
    "    - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
    "    - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span> </b>)\n",
    "        \n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: expanding dimensions** ‚ùì\n",
    "\n",
    "* Use the **expand_dims** to add one dimension at the end of the training data and test data.\n",
    "\n",
    "* Then, print the shapes of `X_train` and `X_test` which should respectively be equal to  $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass  # YOUR CODE HERE\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims (X_test, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last thing to do to prepare your data is to convert your labels to \"*one-hot encode*\" the categories.\n",
    "\n",
    "‚ùì **Question: encoding the labels** ‚ùì \n",
    "\n",
    "* Use **`to_categorical`** to transform your labels. \n",
    "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "pass  # YOUR CODE HERE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_cat= to_categorical(y_train, num_classes=10)\n",
    "y_test_cat= to_categorical(y_test, num_classes=10)\n",
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Architecture and compilation of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
    "\n",
    "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
    "\n",
    "\n",
    "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
    "- a `MaxPool2D` layer with a `pool_size` equal to $ (2, 2) $\n",
    "- a second `Conv2D` layer with 16 filters, each of size $ (3, 3) $, and the `relu` activation function\n",
    "- a second `MaxPool2D` layer with a `pool_size` equal to $ (2, 2) $\n",
    "\n",
    "\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
    "- a last (predictive) layer that is suited for your task\n",
    "\n",
    "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
    "* optimizes the `categorical_crossentropy` \n",
    "* with the `adam` optimizer\n",
    "* and the `accuracy` as the metrics\n",
    "\n",
    "(*NB: you could add more classification metrics if you want but the dataset is well balanced!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(16, (3,3),activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='relu')) # intermediate layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    ### Second Convolution & MaxPooling\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ### Flattening\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ### Model compilation\n",
    "    # YOUR CODE HERE\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = initialize_model()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: number of trainable parameters in a convoluational layer** ‚ùì \n",
    "\n",
    "How many trainable parameters are there in your model?\n",
    "1. Compute them with ***model.summary( )*** first\n",
    "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 8)         136       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5770      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,184\n",
      "Trainable params: 7,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: training a CNN** ‚ùì \n",
    "\n",
    "Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
    "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges... !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model = initialize_model()\n",
    "\n",
    "# Setting the patience with the Early Stopping AND RESTORE THE BEST WEIGHTS\n",
    "es = EarlyStopping(patience = 30, restore_best_weights = True)\n",
    "\n",
    "# Fitting the model and saving the training into a history variable\n",
    "history = model.fit(X_train, y_train_cat,\n",
    "                    validation_split = 0.3,\n",
    "                    epochs = 5,\n",
    "                    batch_size = 16, \n",
    "                    verbose = 0, \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
    "\n",
    "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting and losses üòâ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer:</i></summary>\n",
    "\n",
    "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
    "    \n",
    "Remember that we've just trained our CNN model on $60000$ images from the *train images*.\n",
    "\n",
    "If the chosen batch size is 32: \n",
    "\n",
    "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $  batches are used to compute the `val_loss`\n",
    "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
    "\n",
    "\n",
    "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
    "\n",
    "What is your **`accuracy on the test set?`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
    "\n",
    "üî• You solved what was a very hard problem 30 years ago with your own CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations!**\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
